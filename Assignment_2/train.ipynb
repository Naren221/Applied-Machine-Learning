{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, auc, precision_recall_curve\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import ModelSignature\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location=('file:///c:/Users/naren/OneDrive/Documents/CMI/Semester 4/Applied Machine '\n",
       " 'Learning/Assignment_2/mlruns/712774972690327265'), creation_time=1740668958894, experiment_id='712774972690327265', last_update_time=1740668958894, lifecycle_stage='active', name='Spam Classifier Experiment', tags={}>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize MLflow\n",
    "mlflow.set_tracking_uri('file:mlruns')  # Local directory for tracking\n",
    "mlflow.set_experiment('Spam Classifier Experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data splits\n",
    "train = pd.read_csv('train.csv').dropna()\n",
    "validation = pd.read_csv('validation.csv').dropna()\n",
    "test = pd.read_csv('test.csv').dropna()\n",
    "\n",
    "# Vectorizing the text data using TF-IDF\n",
    "def vectorize_data(train_data, validation_data, test_data):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    X_train = vectorizer.fit_transform(train_data['message'])\n",
    "    X_validation = vectorizer.transform(validation_data['message'])\n",
    "    X_test = vectorizer.transform(test_data['message'])\n",
    "    return X_train, X_validation, X_test, vectorizer\n",
    "\n",
    "X_train, X_validation, X_test, vectorizer = vectorize_data(train, validation, test)\n",
    "\n",
    "# Function to calculate AUCPR\n",
    "def calculate_aucpr(model, X, y_true):\n",
    "    y_scores = model.predict_proba(X)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X)\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_scores, pos_label='spam')\n",
    "    aucpr = auc(recall, precision)\n",
    "    return aucpr\n",
    "\n",
    "# Model training, tracking, and registration with MLflow\n",
    "def train_and_track_model(model_name, model, param_grid, X_train, y_train, X_validation, y_validation):\n",
    "    with mlflow.start_run(run_name=model_name) as run:\n",
    "        # Hyperparameter tuning with GridSearchCV\n",
    "        grid_search = GridSearchCV(model, param_grid, scoring='recall', cv=5, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Evaluation on validation set\n",
    "        val_precision, val_recall, val_accuracy = evaluate_model(best_model, X_validation, y_validation)\n",
    "        aucpr = calculate_aucpr(best_model, X_validation, y_validation)\n",
    "\n",
    "        print(f'{model_name} - AUCPR: {aucpr:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        # Log parameters, metrics, and model in MLflow\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metrics({\n",
    "            'precision': val_precision,\n",
    "            'recall': val_recall,\n",
    "            'accuracy': val_accuracy,\n",
    "            'aucpr': aucpr\n",
    "        })\n",
    "\n",
    "        # Log and register the model\n",
    "        signature = infer_signature(X_validation, best_model.predict(X_validation))\n",
    "        mlflow.sklearn.log_model(best_model, 'model', signature=signature)\n",
    "        mlflow.set_tag('model_name', model_name)\n",
    "\n",
    "        model_uri = f'runs:/{run.info.run_id}/model'\n",
    "        mlflow.register_model(model_uri=model_uri, name='SpamClassifierModel')\n",
    "\n",
    "        return best_model\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model(model, X, y, average='binary'):\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred, pos_label='spam', average=average)\n",
    "    precision = precision_score(y, y_pred, pos_label='spam', average=average)\n",
    "    return precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - AUCPR: 0.9609, Precision: 0.9245, Recall: 0.8448, Accuracy: 0.9709\n",
      "Registered model 'SpamClassifierModel' already exists. Creating a new version of this model...\n",
      "Created version '4' of model 'SpamClassifierModel'.\n",
      "Logistic Regression - AUCPR: 0.9472, Precision: 0.8901, Recall: 0.7823, Accuracy: 0.8700\n",
      "Registered model 'SpamClassifierModel' already exists. Creating a new version of this model...\n",
      "Created version '5' of model 'SpamClassifierModel'.\n",
      "SVM - AUCPR: 0.9513, Precision: 1.0000, Recall: 0.4483, Accuracy: 0.9283\n",
      "Registered model 'SpamClassifierModel' already exists. Creating a new version of this model...\n",
      "Created version '6' of model 'SpamClassifierModel'.\n"
     ]
    }
   ],
   "source": [
    "# Define models and hyperparameter grids\n",
    "models = {\n",
    "    'Naive Bayes': (MultinomialNB(), {'alpha': [0.01, 0.1, 1, 10]}),\n",
    "    'Logistic Regression': (LogisticRegression(), {'C': [0.01, 0.1, 1, 10], 'solver': ['liblinear']}),\n",
    "    'SVM': (SVC(probability=True), {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']})\n",
    "}\n",
    "\n",
    "# Train, track, and register all models\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    train_and_track_model(model_name, model, param_grid, X_train, train['label'], X_validation, validation['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model AUCPR: 0.7900\n"
     ]
    }
   ],
   "source": [
    "logged_model = 'runs:/d1df0f4f00c24fcc8128171054513663/model'\n",
    "model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Get predictions and convert 'spam' to 1 and 'ham' to 0\n",
    "y_scores = model.predict(X_test)\n",
    "y_scores = (y_scores == 'spam').astype(int)\n",
    "\n",
    "# Convert true labels to 1 for 'spam' and 0 for 'ham'\n",
    "y_true = (test['label'] == 'spam').astype(int)\n",
    "\n",
    "# Calculate precision, recall, and AUCPR\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "aucpr = auc(recall, precision)\n",
    "\n",
    "# Print the model selection metric AUCPR\n",
    "print(f\"Model AUCPR: {aucpr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model AUCPR: 0.5650\n"
     ]
    }
   ],
   "source": [
    "# Load the model using the run ID\n",
    "logged_model = 'runs:/b8e832fdb09d4dd0a7fa704c263f4851/model'\n",
    "model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Get predictions and convert 'spam' to 1 and 'ham' to 0\n",
    "y_scores = model.predict(X_test)\n",
    "y_scores = (y_scores == 'spam').astype(int)\n",
    "\n",
    "# Convert true labels to 1 for 'spam' and 0 for 'ham'\n",
    "y_true = (test['label'] == 'spam').astype(int)\n",
    "\n",
    "# Calculate precision, recall, and AUCPR\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "aucpr = auc(recall, precision)\n",
    "\n",
    "# Print the model selection metric AUCPR\n",
    "print(f\"Model AUCPR: {aucpr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model AUCPR: 0.9356\n"
     ]
    }
   ],
   "source": [
    "# Load the model using the run ID\n",
    "logged_model = 'runs:/ce9bc088e0904920a1b0038d6e5077a5/model'\n",
    "model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Get predictions and convert 'spam' to 1 and 'ham' to 0\n",
    "y_scores = model.predict(X_test)\n",
    "y_scores = (y_scores == 'spam').astype(int)\n",
    "\n",
    "# Convert true labels to 1 for 'spam' and 0 for 'ham'\n",
    "y_true = (test['label'] == 'spam').astype(int)\n",
    "\n",
    "# Calculate precision, recall, and AUCPR\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "aucpr = auc(recall, precision)\n",
    "\n",
    "# Print the model selection metric AUCPR\n",
    "print(f\"Model AUCPR: {aucpr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model: **Naive Bayes** with AUCPR: 0.9356"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
